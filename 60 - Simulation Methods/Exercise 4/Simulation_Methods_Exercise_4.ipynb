{"cells":[{"cell_type":"markdown","id":"8643fc23","metadata":{"id":"8643fc23"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","id":"fb451cc7-3e2f-4f66-ae89-ee2f1903b9db","metadata":{"tags":[],"id":"fb451cc7-3e2f-4f66-ae89-ee2f1903b9db"},"source":["# Initialization"]},{"cell_type":"code","execution_count":null,"id":"99b995e8-b646-4f0c-acdf-57db37fce49f","metadata":{"id":"99b995e8-b646-4f0c-acdf-57db37fce49f"},"outputs":[],"source":["import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from matplotlib.widgets import Cursor\n","import pandas as pd\n","\n","matplotlib.use('TkAgg')"]},{"cell_type":"markdown","id":"a2fab6ce-cd25-482b-b1d9-344664d43aee","metadata":{"tags":[],"id":"a2fab6ce-cd25-482b-b1d9-344664d43aee"},"source":["# 1. Show that this is an invertible map. Given any set $S \\subset \\mathbb{R}^2$ with positive measure, can you compute the limit of the measure of $H^{(n)}(S)$ when $n\\rightarrow \\infty$?"]},{"cell_type":"markdown","id":"35f5b55f","metadata":{"id":"35f5b55f"},"source":["Let us demonstrate the invertibility of the map $H$. In fact, we will establish that $H$ is a diffeomorphism, which will prove useful for the second part of the exercise.\n","\n","Given two manifolds, $M$ and $N$, a differential map $f: M \\rightarrow N$ is referred to as a diffeomorphism if it is a bijective function, and its inverse $f^{-1}: N \\rightarrow M$ is also differentiable.\n","\n","It is evident that our function $H$ qualifies as a differential map. The only remaining task is to establish that $H$ is both a bijection and possesses a differentiable inverse. To accomplish this, we will employ the Inverse Function Theorem (IFT). To apply the theorem, we need to verify that the determinant of the Jacobian matrix is non-zero at some point. \n","\n","$$\n","\\operatorname{det}\\left(J_H(x, y)\\right)=\\operatorname{det}\\left[\\begin{array}{cc}\n","-2 a x & 1 \\\\\n","b & 0\n","\\end{array}\\right]=-b \\neq 0 .\n","$$\n","\n","Therefore, according to the IFT, the map $H$ has a locally continuously differentiable inverse at every point in $\\mathbb{R}^2$. Notably, if we prove that $H$ is an injective map, it will establish that $H$ is a diffeomorphism, since injectivity implies the existence of a globally continuously differentiable inverse. To prove that $H$ is injective, let's assume that $H(x, y)=H\\left(x', y'\\right)$ and observe that $(x, y)=\\left(x', y'\\right)$. Hence, $H$ is injective, and consequently, $H$ is a diffeomorphism.\n","\n","Let's now proceed with the second part of the exercise. For any set $S \\subset \\mathbb{R}^2$ with positive measure, it's worth noting that\n","\n","$$\n","\\lim _{n \\rightarrow \\infty} \\mu\\left(H^n(S)\\right)=\\lim _{n \\rightarrow \\infty} \\int_{H^n(S)} 1 d \\mu=\\lim _{n \\rightarrow \\infty}\\left|\\operatorname{det}\\left(J_{H^{(n)}}\\right)\\right| \\int_S 1 d \\mu\n","$$\n","\n","where the last equality is due to the change of variable theorem for diffeomorphisms. Notice that\n","\n","$$\n","\\left|\\operatorname{det}\\left(J_{H^{(n)}}\\right)\\right|=\\left|\\operatorname{det}\\left(\\prod_{k=1}^{n-1} J_H\\left(H^{n-k}\\right) J_H\\right)\\right|=b^n .\n","$$\n","\n","Hence, since $b=0.3$\n","\n","$$\n","\\lim _{n \\rightarrow \\infty} \\mu\\left(H^n(S)\\right)=\\lim _{n \\rightarrow \\infty} b^n \\int_S 1 d \\mu= \\begin{cases}0 & \\text { if } S \\text { is a set of finite measure } \\\\ \\infty & \\text { otherwise. }\\end{cases}\n","$$"]},{"cell_type":"markdown","id":"803ab9b8-d3bb-42cb-b185-4d45ad2612be","metadata":{"tags":[],"id":"803ab9b8-d3bb-42cb-b185-4d45ad2612be"},"source":["# 2. (Optional) Make a plot of the dynamics of $H$. Note that there is an attractor set for many initial conditions. Make a plot of this attracting set. Feel free to zoom into the structure of this attracting set."]},{"cell_type":"code","execution_count":null,"id":"9d2937f2-8c9a-435d-b6f6-f5140f882c13","metadata":{"id":"9d2937f2-8c9a-435d-b6f6-f5140f882c13"},"outputs":[],"source":["def henon_map(x, y, a=1.4, b=0.3):\n","    ''' dissipative Hénon_map function to update the points\n","    '''\n","    x_new = 1 + y - a*(x**2)\n","    y_new = b*x\n","    x_new = np.clip(x_new, -1e10, 1e10)   # For overflow problems\n","    y_new = np.clip(y_new, -1e10, 1e10)   # For overflow problems\n","    \n","    return x_new, y_new\n","\n","  \n","def on_click(event):\n","    ''' on_click function to receive as input the click event\n","    '''\n","    x, y = event.xdata, event.ydata   # Receive the coordinates of the point clicked\n","    plt.plot(x, y, 'k')   # Plot the initial point\n","    for i in range(1000):\n","        x, y = henon_map(x, y)   # Updated to the next points in the map\n","        plt.plot(x, y, 'ko', markersize=0.1)   # Plot the next point\n","    plt.draw()"]},{"cell_type":"code","execution_count":null,"id":"d8935bac-d727-4d1c-bbb3-db37db3c1b4c","metadata":{"id":"d8935bac-d727-4d1c-bbb3-db37db3c1b4c"},"outputs":[],"source":["# Define the global parameter alpha ---------------------------------------------------------\n","a = 1.4\n","b = 0.3\n","\n","# Open a figure -----------------------------------------------------------------------------\n","fig, ax = plt.subplots(figsize=(8,8))\n","\n","# Setup the cursor widget -------------------------------------------------------------------\n","cursor = Cursor(ax, useblit=True, color='red', linewidth=0.1)\n","\n","# Figure settings ---------------------------------------------------------------------------\n","plt.axhline(y=0, color='black', lw=0.5)\n","plt.axvline(x=0, color='black', lw=0.5)\n","ax.set_xlim([-1.5, 1.5])\n","ax.set_ylim([-1.5, 1.5])\n","ax.set_aspect('equal')\n","ax.set_title(f'Dissipative Hénon map with a={a:.2f}, b={b:.2f}')\n","plt.connect('button_press_event', on_click)\n","plt.show()"]},{"cell_type":"markdown","id":"fb2bc47d-07f2-40e3-ba5b-56152a846d2f","metadata":{"id":"fb2bc47d-07f2-40e3-ba5b-56152a846d2f"},"source":["One of the resulting images obtained is presented here for better consultation"]},{"cell_type":"markdown","id":"1ffd0160-4393-4880-8b79-76be7318cb80","metadata":{"id":"1ffd0160-4393-4880-8b79-76be7318cb80"},"source":["![Figure_1-2.png](attachment:Figure_1-2.png)"]},{"cell_type":"markdown","id":"28b3970a-9d81-41f3-8a28-6847775274ef","metadata":{"tags":[],"id":"28b3970a-9d81-41f3-8a28-6847775274ef"},"source":["# 3. This map has a fixed point $p_0$ near $(0.63, 0.19)$. Compute $p_0$ and its stability."]},{"cell_type":"markdown","id":"be6c0f32","metadata":{"id":"be6c0f32"},"source":["We are interested in finding a fixed point for the dissipative hénon map close to $p_0$. Meaning that we are interested in a point $(x,y)$ such that \n","\n","$$henon\\_map(x,y)=(x,y)$$ \n","\n","Thus we can apply a Newton method to find such a point. We can do so to find the zero of the function\n","\n","$$f(x,y)=henon\\_map(x,y)-(x,y)=0$$\n","\n","To do so, we need to compute the Jacobian of such function. By taking the partial derivates the Jacobian can be computed as\n","\n","$$J(x,y)=\\begin{bmatrix} \\frac{\\partial f_x}{\\partial x} & \\frac{\\partial f_x}{\\partial y} \\\\ \\frac{\\partial f_y}{\\partial x} & \\frac{\\partial f_y}{\\partial y} \\end{bmatrix} = \\begin{bmatrix} -2ax & 1 \\\\ b & 0 \\end{bmatrix} - \\mathcal{I}$$"]},{"cell_type":"code","execution_count":null,"id":"13680606","metadata":{"id":"13680606"},"outputs":[],"source":["# Redefine the henon_map function to use as input the coordinates in a vector x -------------\n","def henon_map(x, a=1.4, b=0.3):\n","    ''' henon_map function to update the points\n","    '''\n","    x_new = np.copy(x)   # This is needed because sometimes python applies to the point the transformation when used in a function\n","    x_new[0] = 1 + x[1] - a*(x[0]**2)\n","    x_new[1] = b*x[0]\n","    x_new = np.clip(x_new, -1e10, 1e10)   # For overflow problems\n","    \n","    return x_new\n","\n","def f(x, a=1.4, b=0.3):\n","    ''' Function of which we want to find the zero\n","    '''\n","    x_new = np.copy(x)   # This is needed because sometimes python applies to the point the transformation when used in a function\n","    \n","    return henon_map(x_new, a, b)-x_new\n","\n","# Define the function to compute the Jacobian -----------------------------------------------\n","def Jacobian_f(x, a=1.4, b=0.3):\n","    ''' Jacobian of the function f\n","    '''\n","    x_new = np.copy(x)   # This is needed because sometimes python applies to the point the transformation when used in a function\n","\n","    return np.array([[-2*a*x[0], 1], [b, 0]]) - np.eye(2)"]},{"cell_type":"markdown","id":"de3355ba","metadata":{"id":"de3355ba"},"source":["We can now use a fixed point Newton method in order to compute the fixed point"]},{"cell_type":"code","execution_count":null,"id":"d250a73a","metadata":{"id":"d250a73a","outputId":"a26fbcef-070b-4c6c-86b3-aa4d527298fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["The method converged to the solution: ( 0.6313544770895048 , 0.1894063431268514 )\n","The method converged in 2 iterations\n"]}],"source":["def Newton_method(x0, a=1.4, b=0.3, max_iter=1000, tol=1e-12):\n","    x_1 = x0\n","    for i in range(max_iter):\n","        x_2 = x_1 - np.dot(np.linalg.inv(Jacobian_f(x_1, a, b)),f(x_1, a, b))       # Here computing the inverse using this function is not computationally optimal,\n","        if np.linalg.norm(x_2-x_1) < tol:                                                    # and in this case it could be done by hand. But, since it is not exactly the object\n","            print(\"The method converged to the solution: (\", x_2[0], \",\", x_2[1], \")\")   #  of this exercise, we can use it, as it is conceptually equivalent\n","            print(\"The method converged in\", i, \"iterations\")\n","            return x_2   # Found a fixed point\n","        x_1 = x_2 \n","    \n","    print(\"The fixed point Newton method did not converge to a solution\")\n","    return [np.nan, np.nan]\n","\n","# Apply the fixed point Newton method using an ititial guess from the plotted map -----------\n","p0 = np.array([0.63, 0.19])   # Initial guess\n","x_fixed = Newton_method(p0)"]},{"cell_type":"code","execution_count":null,"id":"a91debda","metadata":{"id":"a91debda","outputId":"79091bd9-71ec-4628-9deb-993225bf4ce8"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------\n","The eigenvalues of the Jacobian in the fixed point are:\n","[-1.92373886  0.15594632]\n","with norm: [1.92373886 0.15594632]\n","--------------------------------------------------------------------------\n","The determinant of the Jacobian in the fixed point is:\n","-0.30000000000000004\n","The trace of the Jacobian in the fixed point is:\n","-1.7677925358506132\n","--------------------------------------------------------------------------\n"]}],"source":["# Define the function to compute the Jacobian -----------------------------------------------\n","def Jacobian_henon(x, a=1.4, b=0.3):\n","    ''' Jacobian of the function f\n","    '''\n","    x_new = np.copy(x)   # This is needed because sometimes python applies to the point the transformation when used in a function\n","\n","    return np.array([[-2*a*x[0], 1], [b, 0]])\n","\n","print(\"--------------------------------------------------------------------------\")\n","print(\"The eigenvalues of the Jacobian in the fixed point are:\")\n","eigval = np.linalg.eigvals(Jacobian_henon(x_fixed))\n","print(eigval)\n","eigvals_norm = abs(np.linalg.eigvals(Jacobian_henon(x_fixed)))\n","print(\"with norm:\", eigvals_norm)\n","print(\"--------------------------------------------------------------------------\")\n","print(\"The determinant of the Jacobian in the fixed point is:\")\n","determinant = np.linalg.det(Jacobian_henon(x_fixed))\n","print(determinant)\n","print(\"The trace of the Jacobian in the fixed point is:\")\n","print(eigval[0]+eigval[1])\n","print(\"--------------------------------------------------------------------------\")"]},{"cell_type":"markdown","id":"766215bf","metadata":{"id":"766215bf"},"source":["Since one eigenvalue, $\\lambda_1 = -1.9237$, has $|\\lambda_1|>1$, and the other eigenvalue, $\\lambda_2 = 0.1559$, has $|\\lambda_2|<1$, the fixed point is a saddle point, meaning it is an unstable fixed point."]},{"cell_type":"markdown","id":"09a5ec43-45ae-4d00-b7c2-42dff42aa8ad","metadata":{"tags":[],"id":"09a5ec43-45ae-4d00-b7c2-42dff42aa8ad"},"source":["# 4. Compute an approximation to the Lyapunov exponent of the attractor for different (at least two) initial conditions. Explain the computational method and discuss the results."]},{"cell_type":"markdown","id":"9563734b","metadata":{"id":"9563734b"},"source":["In order to approximate the Lyapunov exponent of the attractor we can perform the following steps:\n","\n","* Choose an initial point in the phase space of the attractor. Let's call it $(x_0, y_0)$\n","* Compute the trajectory of this initial point using the map equations $$\\begin{cases} x_{n+1} = 1+y_n-ax_n^2 \\\\ y_{n+1} = bx_n \\end{cases}$$ Iterate these equations for a sufficient number of iterations to allow the system to reach the attractor. Let $N$ be the number of iterations\n","* At each iteration, compute the difference between the current trajectory and a nearby trajectory that starts from a slightly perturbed initial point $(x_0+\\epsilon, y_0+\\epsilon)$ is a small perturbation.\n","* Track the evolution of the difference over the iterations using the following equation $$\\Delta_n = \\sqrt( (x_n-x_{n,\\epsilon})^2+(y_n-y_{n,\\epsilon})^2 )$$ where $\\Delta_n$ represents the distance between the two trajectories at iteration $n$, and $x_{n,\\epsilon}$ and $y_{n,\\epsilon}$ are the coordinates of the perturbed trajectory.\n","* Compute the average logarithm of the distance over the iterations $$\\lambda = \\frac{1}{N}\\sum_{n=1}^N ln\\left( \\frac{\\Delta_{n+1}}{\\Delta_n} \\right)$$ This average logarithm corresponds to the estimated Lyapunov exponent for the attractor of the dissipative Hénon map. A positive Lyapunov exponent indicates chaotic behavior, where nearby trajectories diverge exponentially, while a negative Lyapunov exponent suggests convergence or stability.\n","\n","Note that obtaining an accurate estimation of the Lyapunov exponent often requires a large number of iterations and careful consideration of numerical precision. Additionally, it may be necessary to average the Lyapunov exponent over multiple initial conditions to obtain a more reliable result."]},{"cell_type":"code","execution_count":null,"id":"f14e468c","metadata":{"id":"f14e468c","outputId":"bfe68e4c-b319-4a99-97af-82446670a277"},"outputs":[{"name":"stdout","output_type":"stream","text":["Estimated Lyapunov exponent: 0.00047418608391354227\n"]}],"source":["n_iter = 10000\n","epsilon = 1e-3\n","\n","x_1 = np.zeros(2)\n","trajectory_1 = [x_1]\n","for i in range(n_iter-1):\n","    x_new = henon_map(trajectory_1[-1])\n","    trajectory_1.append(x_new)\n","\n","x_2 = x_1 + np.ones(2)*epsilon\n","trajectory_2 = [x_2]\n","for i in range(n_iter-1):\n","    x_new = henon_map(trajectory_2[-1])\n","    trajectory_2.append(x_new)\n","\n","Delta_n = np.zeros(n_iter)\n","for i in range(n_iter):\n","    Delta_n[i] = np.linalg.norm(trajectory_1[i]-trajectory_2[i])\n","\n","sum = 0\n","for i in range(n_iter-1):\n","    sum += np.log(Delta_n[i+1]/Delta_n[i])\n","\n","lamb = sum/n_iter\n","print(\"Estimated Lyapunov exponent:\", lamb)"]},{"cell_type":"markdown","id":"e384f21a","metadata":{"id":"e384f21a"},"source":["# 5. (Optional) From the previous computation, it is possible to derive the full set of Lyapunov exponents of this attractor?"]},{"cell_type":"markdown","id":"90a3e563","metadata":{"id":"90a3e563"},"source":["In order to address this question, we can make an observation that leads us to an interesting result. Assuming that the sum of the first and second characteristic exponents, denoted as $\\lambda_1$ and $\\lambda_2$ respectively, is equal to the natural logarithm of the absolute value of parameter 'b', as stated in the theoretical framework, we can easily derive the second Lyapunov exponent (SLE) and subsequently determine the full set of Lyapunov exponents for this attractor.\n","\n","By utilizing this assumption, we can proceed with the calculations to obtain the SLE. This finding is significant as it allows us to gain further insights into the dynamic behavior of the system."]},{"cell_type":"code","execution_count":null,"id":"aca59781-72c2-4715-aa0c-142c81a38a29","metadata":{"id":"aca59781-72c2-4715-aa0c-142c81a38a29"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}